{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["A6DMT71Dc5qE","iY6s2y5Vd0WA"],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMcPci+Hl+9VkbWcQt4W2bO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Mistral-7B-Instruct-v0.1**"],"metadata":{"id":"-IPopZoocxrx"}},{"cell_type":"markdown","source":["# **Step 1: Libraries**"],"metadata":{"id":"A6DMT71Dc5qE"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"m1gb0V18crrH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710783297842,"user_tz":240,"elapsed":77675,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}},"outputId":"9ef38c37-5be9-4dc6-8ae2-03a96bff2299"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install langchain accelerate BitsAndBytesConfig --quiet"]},{"cell_type":"code","source":["from tqdm import tqdm\n","import pandas as pd\n","import torch\n","import accelerate\n","from langchain import PromptTemplate, HuggingFacePipeline\n","from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline"],"metadata":{"id":"WsTPOa-vcuXl","executionInfo":{"status":"ok","timestamp":1710783305347,"user_tz":240,"elapsed":7510,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# **Step 2: Load Data**"],"metadata":{"id":"iY6s2y5Vd0WA"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0_w7xQnJdzt-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710783424506,"user_tz":240,"elapsed":204908,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}},"outputId":"bfe02c1d-92e8-4d0e-f005-bad26219f390"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Medical_Transcription_Extraction/mtsamples.csv')"],"metadata":{"id":"aVK1vVBE2zpA","executionInfo":{"status":"ok","timestamp":1710783425978,"user_tz":240,"elapsed":206379,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["transcription_list = df['transcription'].to_list()"],"metadata":{"id":"zMWDGeoy28rN","executionInfo":{"status":"ok","timestamp":1710783425978,"user_tz":240,"elapsed":206379,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# **Step 3: Model**"],"metadata":{"id":"klji-HFNd58V"}},{"cell_type":"code","source":["quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n",")"],"metadata":{"id":"dwXEdul54lSc","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"error","timestamp":1710783426413,"user_tz":240,"elapsed":206011,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}},"outputId":"26705700-f727-4aa8-9cc0-19d9480d3743"},"execution_count":9,"outputs":[{"output_type":"error","ename":"PackageNotFoundError","evalue":"No package metadata was found for bitsandbytes","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-3c667e52ef08>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m quantization_config = BitsAndBytesConfig(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbnb_4bit_compute_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbnb_4bit_quant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nf4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbnb_4bit_use_double_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_compute_dtype must be a string or a torch.dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         ):\n","\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \"\"\"\n\u001b[0;32m--> 996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \"\"\"\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", trust_remote_code=True)\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"mistralai/Mistral-7B-Instruct-v0.1\",\n","    trust_remote_code=True,\n","    quantization_config=quantization_config,\n","    low_cpu_mem_usage=True,\n","    device_map=\"auto\"\n","    )"],"metadata":{"id":"5m6Wqq34cxYI","executionInfo":{"status":"aborted","timestamp":1710783426413,"user_tz":240,"elapsed":206011,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generation_config = GenerationConfig.from_pretrained('mistralai/Mistral-7B-Instruct-v0.1')\n","generation_config.max_new_tokens = 1024 # maximum number of new tokens that can be generated by the model\n","generation_config.temperature = 0.7 # randomness of the generated tex\n","generation_config.top_p = 0.95 # diversity of the generated text\n","generation_config.do_sample = True # sampling during the generation process\n","generation_config.repetition_penalty = 1.15 # the degree to which the model should avoid repeating tokens in the generated text\n","\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    return_full_text=True,\n","    generation_config=generation_config,\n",")"],"metadata":{"id":"U__pQWLkv9bx","executionInfo":{"status":"aborted","timestamp":1710783426414,"user_tz":240,"elapsed":206012,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = HuggingFacePipeline(pipeline=pipe)"],"metadata":{"id":"cbp6ff6-2g6L","executionInfo":{"status":"aborted","timestamp":1710783426414,"user_tz":240,"elapsed":206012,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Step 4: Inference**"],"metadata":{"id":"hFHg5_GfeCu1"}},{"cell_type":"code","source":["def get_chatglm_response(transcription):\n","    prompt = f\"\"\"This is a patient's transcription: '{transcription}'\n","    For the given patient's transcription, do the next actions sequentially:\n","    First, propose the patient's age. If there is no words about age, return unknown.\n","    Second, propose no more than ten words that summarize the treatment. If you don't know the treatment, assume '''unknown'''\n","    Note: don't use any other words.\n","    Then, show your response following the next format:\n","    Age: <age>\n","    Treatment: The patient will get <treatment> as treatment.\n","    \"\"\"\n","    prompt = PromptTemplate.from_template(prompt)\n","    response = llm.invoke(prompt.format(), max_length=250)\n","    return response"],"metadata":{"id":"gv9_X4Qe8AZA","executionInfo":{"status":"aborted","timestamp":1710783426414,"user_tz":240,"elapsed":201016,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = []\n","for transcription in tqdm(transcription_list[0:2]):\n","    response = get_chatglm_response(transcription)\n","    res.append(response)\n","print(res)"],"metadata":{"id":"Xn8aQTFo8WaL","executionInfo":{"status":"aborted","timestamp":1710783426414,"user_tz":240,"elapsed":201016,"user":{"displayName":"Hehua Fan","userId":"10532428628985434302"}}},"execution_count":null,"outputs":[]}]}